{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import cv2\n",
    "# You may need to restart your runtime prior to this, to let your installation take effect\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def plot_one_box(x, img, color=None, label=None, line_thickness=None, Inverted=False):\n",
    "# # Plots one bounding box on image img\n",
    "#     tl = line_thickness or 2 # line thickness\n",
    "\n",
    "#     c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "#     cv2.rectangle(img, c1, c2, color, thickness=tl)\n",
    "#     if label:\n",
    "#         tf = tl # font thickness\n",
    "#     t_size = cv2.getTextSize(label, 0, fontScale=tl / 2, thickness=tf)[0]\n",
    "#     if Inverted == True:\n",
    "#         c1 = c2\n",
    "#         c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "#     else:\n",
    "#         c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "\n",
    "#     cv2.rectangle(img, c1, c2, color, -1) # filled\n",
    "#     cv2.putText(\n",
    "#     img,\n",
    "#     label,\n",
    "#     (c1[0], c1[1] - 2),\n",
    "#     0,\n",
    "#     tl / 2,\n",
    "#     [225, 255, 255],\n",
    "#     thickness=tf,\n",
    "#     lineType=cv2.LINE_AA,\n",
    "#     )\n",
    "\n",
    "# # Using readlines()\n",
    "# file1 = open('train.csv', 'r')\n",
    "# Lines = file1.readlines()\n",
    "\n",
    "# count = 0\n",
    "# # Strips the newline character\n",
    "# for line in Lines:\n",
    "#     if count == 0:\n",
    "#         count += 1\n",
    "#         continue\n",
    "\n",
    "#     print(line)\n",
    "#     file_id_path = line.split(',')[1]\n",
    "\n",
    "#     print(file_id_path)\n",
    "#     # open image in cv2\n",
    "#     img = cv2.imread(\"images/\" + file_id_path)\n",
    "#     # cv2.imshow(\"image\", img)\n",
    "#     # cv2.waitKey(20)\n",
    "#     # cv2.destroyAllWindows()\n",
    "#     h, w, c = img.shape\n",
    "#     cat = line.split(',')[2]\n",
    "#     xmax = int(float(line.split(',')[3])) * 2\n",
    "#     xmin = int(float(line.split(',')[4])) * 2\n",
    "#     ymax = int(float(line.split(',')[5])) * 2\n",
    "#     ymin = int(float(line.split(',')[6])) * 2\n",
    "#     # plot the box\n",
    "#     plot_one_box([xmin, ymin, xmax, ymax], img, color=(0, 255, 0), label=cat, line_thickness=2)\n",
    "#     # save the image\n",
    "#     # you might need to create the folder \"drawn\" first!\n",
    "#     cv2.imwrite(\"drawn/\" + file_id_path, img)\n",
    "#     print(\"Line {}: {}\".format(count, line.strip()))\n",
    "#     count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_coco(file_dir,destination_dir):\n",
    "    path = file_dir\n",
    "    save_json_path = destination_dir+'/traincoco.json'\n",
    "    \n",
    "    # clmns = ['class','xmin','ymin','xmax','ymax','filename','width','height']\n",
    "    clmns =  [ \"class\",\t\"image_path\",\t\"name\",\t\"xmax\",\t\"xmin\",\t\"ymax\",\t\"ymin\"]\n",
    "\n",
    "    data = pd.read_csv(path, names = clmns, header=None)\n",
    "    data = data[1:]\n",
    "    \n",
    "    mul = 2\n",
    "    data['xmax'] = data['xmax'].astype(float).astype(int) * mul\n",
    "    data['xmin'] = data['xmin'].astype(float).astype(int) * mul\n",
    "    data['ymax'] = data['ymax'].astype(float).astype(int) * mul\n",
    "    data['ymin'] = data['ymin'].astype(float).astype(int) * mul\n",
    "    \n",
    "    images = []\n",
    "    categories = []\n",
    "    annotations = []\n",
    "    data['fileid'] = data['image_path'].astype('category').cat.codes\n",
    "    # data['categoryid']= pd.Categorical(data['name'],ordered= True).codes\n",
    "    data['categoryid'] = data['class'].astype(float).astype(int)\n",
    "    data['annid'] = data.index\n",
    "    classes = data['name'].unique()\n",
    "    def image(row):\n",
    "        image = {}\n",
    "        image[\"height\"] = 1080\n",
    "        image[\"width\"] = 1920\n",
    "        image[\"id\"] = row.fileid\n",
    "        image[\"file_name\"] = row.image_path\n",
    "        return image\n",
    "    \n",
    "    def category(row):\n",
    "        category = {}\n",
    "        category[\"supercategory\"] = 'None'\n",
    "        category[\"id\"] = row.categoryid \n",
    "\n",
    "        category[\"name\"] = row[3]\n",
    "        return category\n",
    "    \n",
    "    def annotation(row):\n",
    "        annotation = {}\n",
    "        area = (row.xmax)*(row.ymax)\n",
    "        annotation[\"segmentation\"] = []\n",
    "        annotation[\"iscrowd\"] = 0\n",
    "        annotation[\"area\"] = area\n",
    "        annotation[\"image_id\"] = row.fileid\n",
    "        annotation[\"bbox\"] = [row.xmin, row.ymin, row.xmax +row.xmin,row.ymax+row.ymin ]\n",
    "        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n",
    "        annotation[\"category_id\"] = row.categoryid \n",
    "        annotation[\"id\"] = row.annid\n",
    "        return annotation\n",
    "    \n",
    "    for row in data.itertuples():\n",
    "        annotations.append(annotation(row))\n",
    "    imagedf = data.drop_duplicates(subset=['fileid']).sort_values(by='fileid')\n",
    "    for row in imagedf.itertuples():\n",
    "        images.append(image(row))\n",
    "    catdf = data.drop_duplicates(subset=['categoryid']).sort_values(by='categoryid')\n",
    "    for row in catdf.itertuples():\n",
    "        categories.append(category(row))\n",
    "\n",
    "    data_coco = {}\n",
    "    data_coco[\"images\"] = images\n",
    "    data_coco[\"categories\"] = categories\n",
    "    data_coco[\"annotations\"] = annotations\n",
    "    json.dump(data_coco, open(save_json_path, \"w\"), indent=4)\n",
    "    return classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GARBAGE' 'BAD_BILLBOARD' 'SAND_ON_ROAD' 'GRAFFITI' 'POTHOLES'\n",
      " 'CLUTTER_SIDEWALK' 'CONSTRUCTION_ROAD' 'BROKEN_SIGNAGE' 'UNKEPT_FACADE'\n",
      " 'FADED_SIGNAGE' 'BAD_STREETLIGHT']\n"
     ]
    }
   ],
   "source": [
    "file_dir = 'train.csv'\n",
    "destination_dir = 'coco'\n",
    "classes = csv_to_coco(file_dir,destination_dir)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_board_dicts(imgdir):\n",
    "    json_file = imgdir+\"/traincoco.json\" #Fetch the json file\n",
    "    with open(json_file) as f:\n",
    "        dataset_dicts = json.load(f)\n",
    "    # for i in dataset_dicts:\n",
    "    #     filename = i[\"file_name\"] \n",
    "    #     i[\"file_name\"] = imgdir+\"/\"+filename \n",
    "    #     for j in i[\"annotations\"]:\n",
    "    #         j[\"bbox_mode\"] = BoxMode.XYWH_ABS #Setting the required Box Mode\n",
    "    #         j[\"category_id\"] = int(j[\"category_id\"])\n",
    "    return dataset_dicts\n",
    "\n",
    "# for d in [\"train\", \"val\"]:\n",
    "dataset = json.load(open(\"coco/traincoco.json\"))\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"smartcity\", {}, \"./coco/traincoco.json\", \"./images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/27 16:56:01 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[01/27 16:56:01 d2.data.datasets.coco]: \u001b[0mLoaded 7874 images in COCO format from ./coco/traincoco.json\n"
     ]
    }
   ],
   "source": [
    "metadata = MetadataCatalog.get(\"smartcity\")\n",
    "dataset_dicts = DatasetCatalog.get(\"smartcity\")\n",
    "# print(dataset_dicts), print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "for d in random.sample(dataset_dicts, 10):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    frame = vis.get_image()[:, :, ::-1]\n",
    "    cv2.imshow(\"\",frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "trailing comma not allowed without surrounding parentheses (3510773385.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [9]\u001b[1;36m\u001b[0m\n\u001b[1;33m    from detectron2.engine import DefaultTrainer,\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m trailing comma not allowed without surrounding parentheses\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "import os\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")) #Get the basic model configuration from the model zoo \n",
    "cfg.DATASETS.TRAIN = (\"smartcity\",) #Passing the Train and Validation sets\n",
    "cfg.MODEL.DEVICE = \"cuda\"\n",
    "cfg.DATALOADER.NUM_WORKERS = 4 # Number of data loading threads\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4 # Number of images per batch across all machines.\n",
    "cfg.SOLVER.BASE_LR = 0.0125  # pick a good LearningRate\n",
    "cfg.SOLVER.MAX_ITER = 1500  #No. of iterations   \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256  \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 11 # No. of classes \n",
    "# cfg.TEST.EVAL_PERIOD = 500 # No. of iterations after which the Validation Set is evaluated. \n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919d74488b7f903726046d94a3db12ed6078364356a89db739a4dc274728573d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
