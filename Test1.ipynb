{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import cv2\n",
    "# You may need to restart your runtime prior to this, to let your installation take effect\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def plot_one_box(x, img, color=None, label=None, line_thickness=None, Inverted=False):\n",
    "# # Plots one bounding box on image img\n",
    "#     tl = line_thickness or 2 # line thickness\n",
    "\n",
    "#     c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "#     cv2.rectangle(img, c1, c2, color, thickness=tl)\n",
    "#     if label:\n",
    "#         tf = tl # font thickness\n",
    "#     t_size = cv2.getTextSize(label, 0, fontScale=tl / 2, thickness=tf)[0]\n",
    "#     if Inverted == True:\n",
    "#         c1 = c2\n",
    "#         c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "#     else:\n",
    "#         c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "\n",
    "#     cv2.rectangle(img, c1, c2, color, -1) # filled\n",
    "#     cv2.putText(\n",
    "#     img,\n",
    "#     label,\n",
    "#     (c1[0], c1[1] - 2),\n",
    "#     0,\n",
    "#     tl / 2,\n",
    "#     [225, 255, 255],\n",
    "#     thickness=tf,\n",
    "#     lineType=cv2.LINE_AA,\n",
    "#     )\n",
    "\n",
    "# # Using readlines()\n",
    "# file1 = open('train.csv', 'r')\n",
    "# Lines = file1.readlines()\n",
    "\n",
    "# count = 0\n",
    "# # Strips the newline character\n",
    "# for line in Lines:\n",
    "#     if count == 0:\n",
    "#         count += 1\n",
    "#         continue\n",
    "\n",
    "#     print(line)\n",
    "#     file_id_path = line.split(',')[1]\n",
    "\n",
    "#     print(file_id_path)\n",
    "#     # open image in cv2\n",
    "#     img = cv2.imread(\"images/\" + file_id_path)\n",
    "#     # cv2.imshow(\"image\", img)\n",
    "#     # cv2.waitKey(20)\n",
    "#     # cv2.destroyAllWindows()\n",
    "#     h, w, c = img.shape\n",
    "#     cat = line.split(',')[2]\n",
    "#     xmax = int(float(line.split(',')[3])) * 2\n",
    "#     xmin = int(float(line.split(',')[4])) * 2\n",
    "#     ymax = int(float(line.split(',')[5])) * 2\n",
    "#     ymin = int(float(line.split(',')[6])) * 2\n",
    "#     # plot the box\n",
    "#     plot_one_box([xmin, ymin, xmax, ymax], img, color=(0, 255, 0), label=cat, line_thickness=2)\n",
    "#     # save the image\n",
    "#     # you might need to create the folder \"drawn\" first!\n",
    "#     cv2.imwrite(\"drawn/\" + file_id_path, img)\n",
    "#     print(\"Line {}: {}\".format(count, line.strip()))\n",
    "#     count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_coco(file_dir,destination_dir):\n",
    "    path = file_dir\n",
    "    save_json_path = destination_dir+'/traincoco.json'\n",
    "    \n",
    "    # clmns = ['class','xmin','ymin','xmax','ymax','filename','width','height']\n",
    "    clmns =  [ \"class\",\t\"image_path\",\t\"name\",\t\"xmax\",\t\"xmin\",\t\"ymax\",\t\"ymin\"]\n",
    "\n",
    "    data = pd.read_csv(path, names = clmns, header=None)\n",
    "    data = data[1:]\n",
    "    \n",
    "    mul = 2\n",
    "    data['xmax'] = data['xmax'].astype(float).astype(int) * mul\n",
    "    data['xmin'] = data['xmin'].astype(float).astype(int) * mul\n",
    "    data['ymax'] = data['ymax'].astype(float).astype(int) * mul\n",
    "    data['ymin'] = data['ymin'].astype(float).astype(int) * mul\n",
    "    \n",
    "    images = []\n",
    "    categories = []\n",
    "    annotations = []\n",
    "    data['fileid'] = data['image_path'].astype('category').cat.codes\n",
    "    # data['categoryid']= pd.Categorical(data['name'],ordered= True).codes\n",
    "    data['categoryid'] = data['class'].astype(float).astype(int)\n",
    "    data['annid'] = data.index\n",
    "    classes = data['name'].unique()\n",
    "    def image(row):\n",
    "        image = {}\n",
    "        image[\"height\"] = 1080\n",
    "        image[\"width\"] = 1920\n",
    "        image[\"id\"] = row.fileid\n",
    "        image[\"file_name\"] = row.image_path\n",
    "        return image\n",
    "    \n",
    "    def category(row):\n",
    "        category = {}\n",
    "        category[\"supercategory\"] = 'None'\n",
    "        category[\"id\"] = row.categoryid \n",
    "\n",
    "        category[\"name\"] = row[3]\n",
    "        return category\n",
    "    \n",
    "    def annotation(row):\n",
    "        annotation = {}\n",
    "        area = (row.xmax)*(row.ymax)\n",
    "        annotation[\"segmentation\"] = []\n",
    "        annotation[\"iscrowd\"] = 0\n",
    "        annotation[\"area\"] = area\n",
    "        annotation[\"image_id\"] = row.fileid\n",
    "        annotation[\"bbox\"] = [row.xmin, row.ymin, row.xmax +row.xmin,row.ymax+row.ymin ]\n",
    "        annotation[\"bbox_mode\"] = BoxMode.XYXY_ABS\n",
    "        annotation[\"category_id\"] = row.categoryid \n",
    "        annotation[\"id\"] = row.annid\n",
    "        return annotation\n",
    "    \n",
    "    for row in data.itertuples():\n",
    "        annotations.append(annotation(row))\n",
    "    imagedf = data.drop_duplicates(subset=['fileid']).sort_values(by='fileid')\n",
    "    for row in imagedf.itertuples():\n",
    "        images.append(image(row))\n",
    "    catdf = data.drop_duplicates(subset=['categoryid']).sort_values(by='categoryid')\n",
    "    for row in catdf.itertuples():\n",
    "        categories.append(category(row))\n",
    "\n",
    "    data_coco = {}\n",
    "    data_coco[\"images\"] = images\n",
    "    data_coco[\"categories\"] = categories\n",
    "    data_coco[\"annotations\"] = annotations\n",
    "    json.dump(data_coco, open(save_json_path, \"w\"), indent=4)\n",
    "    return classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GARBAGE' 'BAD_BILLBOARD' 'SAND_ON_ROAD' 'GRAFFITI' 'POTHOLES'\n",
      " 'CLUTTER_SIDEWALK' 'CONSTRUCTION_ROAD' 'BROKEN_SIGNAGE' 'UNKEPT_FACADE'\n",
      " 'FADED_SIGNAGE' 'BAD_STREETLIGHT']\n"
     ]
    }
   ],
   "source": [
    "file_dir = 'train.csv'\n",
    "destination_dir = 'coco'\n",
    "classes = csv_to_coco(file_dir,destination_dir)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_board_dicts(imgdir):\n",
    "    json_file = imgdir+\"/traincoco.json\" #Fetch the json file\n",
    "    with open(json_file) as f:\n",
    "        dataset_dicts = json.load(f)\n",
    "    # for i in dataset_dicts:\n",
    "    #     filename = i[\"file_name\"] \n",
    "    #     i[\"file_name\"] = imgdir+\"/\"+filename \n",
    "    #     for j in i[\"annotations\"]:\n",
    "    #         j[\"bbox_mode\"] = BoxMode.XYWH_ABS #Setting the required Box Mode\n",
    "    #         j[\"category_id\"] = int(j[\"category_id\"])\n",
    "    return dataset_dicts\n",
    "\n",
    "# for d in [\"train\", \"val\"]:\n",
    "dataset = json.load(open(\"coco/traincoco.json\"))\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"smartcity\", {}, \"./coco/traincoco.json\", \"./images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/27 18:52:11 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[01/27 18:52:11 d2.data.datasets.coco]: \u001b[0mLoaded 7874 images in COCO format from ./coco/traincoco.json\n"
     ]
    }
   ],
   "source": [
    "metadata = MetadataCatalog.get(\"smartcity\")\n",
    "dataset_dicts = DatasetCatalog.get(\"smartcity\")\n",
    "# print(dataset_dicts), print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "for d in random.sample(dataset_dicts, 10):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    frame = vis.get_image()[:, :, ::-1]\n",
    "    cv2.imshow(\"\",frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/27 20:06:00 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=12, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/27 20:06:00 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[01/27 20:06:00 d2.data.datasets.coco]: \u001b[0mLoaded 7874 images in COCO format from ./coco/traincoco.json\n",
      "\u001b[32m[01/27 20:06:00 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 7874 images left.\n",
      "\u001b[32m[01/27 20:06:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/27 20:06:00 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/27 20:06:00 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/27 20:06:00 d2.data.common]: \u001b[0mSerializing 7874 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/27 20:06:00 d2.data.common]: \u001b[0mSerialized dataset takes 2.23 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/27 20:06:00 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[01/27 20:06:01 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (44, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (44,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/27 20:06:01 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[01/27 20:06:16 d2.utils.events]: \u001b[0m eta: 1:19:23  iter: 19  total_loss: 2.328  loss_cls: 2.058  loss_box_reg: 0.06648  loss_rpn_cls: 0.1414  loss_rpn_loc: 0.02007  time: 0.4733  data_time: 0.2915  lr: 0.00024976  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:06:26 d2.utils.events]: \u001b[0m eta: 1:19:49  iter: 39  total_loss: 0.8174  loss_cls: 0.416  loss_box_reg: 0.2916  loss_rpn_cls: 0.04708  loss_rpn_loc: 0.02463  time: 0.4773  data_time: 0.0026  lr: 0.00049951  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:06:36 d2.utils.events]: \u001b[0m eta: 1:19:28  iter: 59  total_loss: 0.8104  loss_cls: 0.4007  loss_box_reg: 0.3644  loss_rpn_cls: 0.02928  loss_rpn_loc: 0.01548  time: 0.4765  data_time: 0.0026  lr: 0.00074926  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:06:45 d2.utils.events]: \u001b[0m eta: 1:19:07  iter: 79  total_loss: 0.8867  loss_cls: 0.4096  loss_box_reg: 0.425  loss_rpn_cls: 0.02004  loss_rpn_loc: 0.0167  time: 0.4764  data_time: 0.0026  lr: 0.00099901  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:06:55 d2.utils.events]: \u001b[0m eta: 1:19:20  iter: 99  total_loss: 0.9203  loss_cls: 0.3994  loss_box_reg: 0.4737  loss_rpn_cls: 0.01645  loss_rpn_loc: 0.01676  time: 0.4790  data_time: 0.0027  lr: 0.0012488  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:07:05 d2.utils.events]: \u001b[0m eta: 1:19:15  iter: 119  total_loss: 0.842  loss_cls: 0.3899  loss_box_reg: 0.4245  loss_rpn_cls: 0.01166  loss_rpn_loc: 0.01229  time: 0.4803  data_time: 0.0028  lr: 0.0014985  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:07:14 d2.utils.events]: \u001b[0m eta: 1:19:32  iter: 139  total_loss: 0.9258  loss_cls: 0.4039  loss_box_reg: 0.4492  loss_rpn_cls: 0.0125  loss_rpn_loc: 0.01674  time: 0.4822  data_time: 0.0026  lr: 0.0017483  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:07:24 d2.utils.events]: \u001b[0m eta: 1:19:38  iter: 159  total_loss: 0.8855  loss_cls: 0.389  loss_box_reg: 0.4445  loss_rpn_cls: 0.01344  loss_rpn_loc: 0.01482  time: 0.4830  data_time: 0.0026  lr: 0.001998  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:07:34 d2.utils.events]: \u001b[0m eta: 1:19:31  iter: 179  total_loss: 0.8405  loss_cls: 0.3754  loss_box_reg: 0.4218  loss_rpn_cls: 0.01094  loss_rpn_loc: 0.01426  time: 0.4835  data_time: 0.0027  lr: 0.0022478  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:07:44 d2.utils.events]: \u001b[0m eta: 1:19:25  iter: 199  total_loss: 0.9202  loss_cls: 0.4435  loss_box_reg: 0.4488  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.01382  time: 0.4837  data_time: 0.0027  lr: 0.0024975  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:07:53 d2.utils.events]: \u001b[0m eta: 1:19:18  iter: 219  total_loss: 0.8442  loss_cls: 0.3776  loss_box_reg: 0.4158  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.01423  time: 0.4840  data_time: 0.0027  lr: 0.0027473  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:08:03 d2.utils.events]: \u001b[0m eta: 1:19:17  iter: 239  total_loss: 0.7233  loss_cls: 0.3237  loss_box_reg: 0.3781  loss_rpn_cls: 0.01324  loss_rpn_loc: 0.01363  time: 0.4850  data_time: 0.0027  lr: 0.002997  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:08:13 d2.utils.events]: \u001b[0m eta: 1:19:09  iter: 259  total_loss: 0.7997  loss_cls: 0.3833  loss_box_reg: 0.4194  loss_rpn_cls: 0.0101  loss_rpn_loc: 0.01507  time: 0.4851  data_time: 0.0028  lr: 0.0032468  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:08:23 d2.utils.events]: \u001b[0m eta: 1:19:00  iter: 279  total_loss: 0.7522  loss_cls: 0.3539  loss_box_reg: 0.3821  loss_rpn_cls: 0.008488  loss_rpn_loc: 0.01488  time: 0.4854  data_time: 0.0027  lr: 0.0034965  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:08:33 d2.utils.events]: \u001b[0m eta: 1:18:49  iter: 299  total_loss: 0.8721  loss_cls: 0.3853  loss_box_reg: 0.424  loss_rpn_cls: 0.008421  loss_rpn_loc: 0.01406  time: 0.4852  data_time: 0.0026  lr: 0.0037463  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:08:42 d2.utils.events]: \u001b[0m eta: 1:18:40  iter: 319  total_loss: 0.8261  loss_cls: 0.3815  loss_box_reg: 0.3804  loss_rpn_cls: 0.01101  loss_rpn_loc: 0.01324  time: 0.4852  data_time: 0.0028  lr: 0.003996  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:08:52 d2.utils.events]: \u001b[0m eta: 1:18:32  iter: 339  total_loss: 0.7705  loss_cls: 0.3469  loss_box_reg: 0.3813  loss_rpn_cls: 0.01078  loss_rpn_loc: 0.01362  time: 0.4853  data_time: 0.0027  lr: 0.0042458  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:09:02 d2.utils.events]: \u001b[0m eta: 1:18:25  iter: 359  total_loss: 0.8566  loss_cls: 0.3792  loss_box_reg: 0.4028  loss_rpn_cls: 0.02031  loss_rpn_loc: 0.01673  time: 0.4857  data_time: 0.0027  lr: 0.0044955  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:09:12 d2.utils.events]: \u001b[0m eta: 1:18:18  iter: 379  total_loss: 0.715  loss_cls: 0.3417  loss_box_reg: 0.3729  loss_rpn_cls: 0.01042  loss_rpn_loc: 0.01393  time: 0.4860  data_time: 0.0028  lr: 0.0047453  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:09:21 d2.utils.events]: \u001b[0m eta: 1:18:13  iter: 399  total_loss: 0.7219  loss_cls: 0.3232  loss_box_reg: 0.3853  loss_rpn_cls: 0.01286  loss_rpn_loc: 0.01201  time: 0.4861  data_time: 0.0026  lr: 0.004995  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:09:31 d2.utils.events]: \u001b[0m eta: 1:18:10  iter: 419  total_loss: 0.7708  loss_cls: 0.3664  loss_box_reg: 0.3684  loss_rpn_cls: 0.01368  loss_rpn_loc: 0.01266  time: 0.4864  data_time: 0.0025  lr: 0.0052448  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:09:41 d2.utils.events]: \u001b[0m eta: 1:18:00  iter: 439  total_loss: 0.8149  loss_cls: 0.3512  loss_box_reg: 0.3979  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.01253  time: 0.4862  data_time: 0.0027  lr: 0.0054945  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:09:51 d2.utils.events]: \u001b[0m eta: 1:17:54  iter: 459  total_loss: 0.8067  loss_cls: 0.3725  loss_box_reg: 0.3913  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.01783  time: 0.4865  data_time: 0.0028  lr: 0.0057443  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:10:01 d2.utils.events]: \u001b[0m eta: 1:17:44  iter: 479  total_loss: 0.7497  loss_cls: 0.3283  loss_box_reg: 0.3783  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.01185  time: 0.4867  data_time: 0.0027  lr: 0.005994  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:10:11 d2.utils.events]: \u001b[0m eta: 1:17:38  iter: 499  total_loss: 0.8024  loss_cls: 0.3719  loss_box_reg: 0.3781  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.01882  time: 0.4871  data_time: 0.0026  lr: 0.0062438  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:10:20 d2.utils.events]: \u001b[0m eta: 1:17:31  iter: 519  total_loss: 0.8002  loss_cls: 0.3832  loss_box_reg: 0.3897  loss_rpn_cls: 0.01197  loss_rpn_loc: 0.01305  time: 0.4871  data_time: 0.0026  lr: 0.0064935  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:10:30 d2.utils.events]: \u001b[0m eta: 1:17:20  iter: 539  total_loss: 0.771  loss_cls: 0.3539  loss_box_reg: 0.381  loss_rpn_cls: 0.01029  loss_rpn_loc: 0.01632  time: 0.4872  data_time: 0.0025  lr: 0.0067433  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:10:40 d2.utils.events]: \u001b[0m eta: 1:17:13  iter: 559  total_loss: 0.7575  loss_cls: 0.3306  loss_box_reg: 0.3867  loss_rpn_cls: 0.01121  loss_rpn_loc: 0.01217  time: 0.4874  data_time: 0.0025  lr: 0.006993  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:10:50 d2.utils.events]: \u001b[0m eta: 1:17:05  iter: 579  total_loss: 0.8166  loss_cls: 0.3643  loss_box_reg: 0.4035  loss_rpn_cls: 0.006036  loss_rpn_loc: 0.01228  time: 0.4875  data_time: 0.0028  lr: 0.0072428  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:11:00 d2.utils.events]: \u001b[0m eta: 1:16:57  iter: 599  total_loss: 0.7646  loss_cls: 0.3598  loss_box_reg: 0.371  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.01423  time: 0.4877  data_time: 0.0028  lr: 0.0074925  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:11:10 d2.utils.events]: \u001b[0m eta: 1:16:48  iter: 619  total_loss: 0.8416  loss_cls: 0.353  loss_box_reg: 0.4085  loss_rpn_cls: 0.01217  loss_rpn_loc: 0.01654  time: 0.4879  data_time: 0.0026  lr: 0.0077423  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:11:19 d2.utils.events]: \u001b[0m eta: 1:16:39  iter: 639  total_loss: 0.7889  loss_cls: 0.3548  loss_box_reg: 0.3901  loss_rpn_cls: 0.01043  loss_rpn_loc: 0.01247  time: 0.4878  data_time: 0.0027  lr: 0.007992  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:11:29 d2.utils.events]: \u001b[0m eta: 1:16:30  iter: 659  total_loss: 0.7655  loss_cls: 0.3122  loss_box_reg: 0.3948  loss_rpn_cls: 0.009831  loss_rpn_loc: 0.01192  time: 0.4879  data_time: 0.0026  lr: 0.0082418  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:11:39 d2.utils.events]: \u001b[0m eta: 1:16:21  iter: 679  total_loss: 0.7303  loss_cls: 0.3332  loss_box_reg: 0.3539  loss_rpn_cls: 0.009239  loss_rpn_loc: 0.01439  time: 0.4880  data_time: 0.0026  lr: 0.0084915  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:11:49 d2.utils.events]: \u001b[0m eta: 1:16:12  iter: 699  total_loss: 0.7763  loss_cls: 0.3233  loss_box_reg: 0.3853  loss_rpn_cls: 0.0155  loss_rpn_loc: 0.01309  time: 0.4881  data_time: 0.0026  lr: 0.0087413  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:11:59 d2.utils.events]: \u001b[0m eta: 1:16:08  iter: 719  total_loss: 0.6966  loss_cls: 0.346  loss_box_reg: 0.3698  loss_rpn_cls: 0.009937  loss_rpn_loc: 0.01367  time: 0.4885  data_time: 0.0027  lr: 0.008991  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:12:09 d2.utils.events]: \u001b[0m eta: 1:15:59  iter: 739  total_loss: 0.7479  loss_cls: 0.3384  loss_box_reg: 0.3687  loss_rpn_cls: 0.009578  loss_rpn_loc: 0.01444  time: 0.4886  data_time: 0.0028  lr: 0.0092408  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:12:18 d2.utils.events]: \u001b[0m eta: 1:15:48  iter: 759  total_loss: 0.7207  loss_cls: 0.3382  loss_box_reg: 0.3569  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.01086  time: 0.4886  data_time: 0.0026  lr: 0.0094905  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:12:29 d2.utils.events]: \u001b[0m eta: 1:15:40  iter: 779  total_loss: 0.7891  loss_cls: 0.343  loss_box_reg: 0.3965  loss_rpn_cls: 0.01346  loss_rpn_loc: 0.01192  time: 0.4901  data_time: 0.0028  lr: 0.0097403  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:12:39 d2.utils.events]: \u001b[0m eta: 1:15:32  iter: 799  total_loss: 0.719  loss_cls: 0.3247  loss_box_reg: 0.3824  loss_rpn_cls: 0.01822  loss_rpn_loc: 0.01485  time: 0.4904  data_time: 0.0026  lr: 0.00999  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:12:50 d2.utils.events]: \u001b[0m eta: 1:15:25  iter: 819  total_loss: 0.737  loss_cls: 0.358  loss_box_reg: 0.3703  loss_rpn_cls: 0.01239  loss_rpn_loc: 0.01465  time: 0.4917  data_time: 0.0027  lr: 0.01024  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:13:01 d2.utils.events]: \u001b[0m eta: 1:15:16  iter: 839  total_loss: 0.6474  loss_cls: 0.2944  loss_box_reg: 0.3217  loss_rpn_cls: 0.01073  loss_rpn_loc: 0.01123  time: 0.4929  data_time: 0.0027  lr: 0.01049  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:13:12 d2.utils.events]: \u001b[0m eta: 1:15:08  iter: 859  total_loss: 0.6781  loss_cls: 0.3175  loss_box_reg: 0.3287  loss_rpn_cls: 0.008777  loss_rpn_loc: 0.01518  time: 0.4944  data_time: 0.0027  lr: 0.010739  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:13:23 d2.utils.events]: \u001b[0m eta: 1:15:00  iter: 879  total_loss: 0.8166  loss_cls: 0.369  loss_box_reg: 0.4042  loss_rpn_cls: 0.01382  loss_rpn_loc: 0.01551  time: 0.4950  data_time: 0.0027  lr: 0.010989  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:13:35 d2.utils.events]: \u001b[0m eta: 1:14:53  iter: 899  total_loss: 0.7169  loss_cls: 0.3382  loss_box_reg: 0.3642  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.01606  time: 0.4974  data_time: 0.0027  lr: 0.011239  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:13:45 d2.utils.events]: \u001b[0m eta: 1:14:44  iter: 919  total_loss: 0.7868  loss_cls: 0.3384  loss_box_reg: 0.3892  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.01667  time: 0.4977  data_time: 0.0026  lr: 0.011489  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:13:57 d2.utils.events]: \u001b[0m eta: 1:14:35  iter: 939  total_loss: 0.7754  loss_cls: 0.3665  loss_box_reg: 0.3998  loss_rpn_cls: 0.01064  loss_rpn_loc: 0.01415  time: 0.4999  data_time: 0.0026  lr: 0.011738  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:14:07 d2.utils.events]: \u001b[0m eta: 1:14:24  iter: 959  total_loss: 0.6849  loss_cls: 0.3586  loss_box_reg: 0.365  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.01354  time: 0.4997  data_time: 0.0027  lr: 0.011988  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:14:17 d2.utils.events]: \u001b[0m eta: 1:14:16  iter: 979  total_loss: 0.7243  loss_cls: 0.3154  loss_box_reg: 0.3822  loss_rpn_cls: 0.007498  loss_rpn_loc: 0.009998  time: 0.5000  data_time: 0.0029  lr: 0.012238  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:14:27 d2.utils.events]: \u001b[0m eta: 1:14:06  iter: 999  total_loss: 0.8149  loss_cls: 0.3721  loss_box_reg: 0.4238  loss_rpn_cls: 0.008946  loss_rpn_loc: 0.01464  time: 0.5001  data_time: 0.0026  lr: 0.012488  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:14:39 d2.utils.events]: \u001b[0m eta: 1:13:58  iter: 1019  total_loss: 0.7696  loss_cls: 0.346  loss_box_reg: 0.3954  loss_rpn_cls: 0.009107  loss_rpn_loc: 0.01268  time: 0.5023  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:14:50 d2.utils.events]: \u001b[0m eta: 1:13:51  iter: 1039  total_loss: 0.6108  loss_cls: 0.2949  loss_box_reg: 0.2858  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.01279  time: 0.5026  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:15:00 d2.utils.events]: \u001b[0m eta: 1:13:42  iter: 1059  total_loss: 0.765  loss_cls: 0.3769  loss_box_reg: 0.3543  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.01378  time: 0.5024  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:15:09 d2.utils.events]: \u001b[0m eta: 1:13:32  iter: 1079  total_loss: 0.789  loss_cls: 0.3761  loss_box_reg: 0.432  loss_rpn_cls: 0.009402  loss_rpn_loc: 0.0145  time: 0.5020  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:15:19 d2.utils.events]: \u001b[0m eta: 1:13:23  iter: 1099  total_loss: 0.7053  loss_cls: 0.3091  loss_box_reg: 0.3656  loss_rpn_cls: 0.01092  loss_rpn_loc: 0.01313  time: 0.5017  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:15:29 d2.utils.events]: \u001b[0m eta: 1:13:17  iter: 1119  total_loss: 0.7831  loss_cls: 0.321  loss_box_reg: 0.3644  loss_rpn_cls: 0.0169  loss_rpn_loc: 0.01437  time: 0.5018  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:15:41 d2.utils.events]: \u001b[0m eta: 1:13:11  iter: 1139  total_loss: 0.733  loss_cls: 0.35  loss_box_reg: 0.4138  loss_rpn_cls: 0.01196  loss_rpn_loc: 0.01324  time: 0.5035  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:15:52 d2.utils.events]: \u001b[0m eta: 1:13:06  iter: 1159  total_loss: 0.6703  loss_cls: 0.3249  loss_box_reg: 0.3323  loss_rpn_cls: 0.01397  loss_rpn_loc: 0.01426  time: 0.5045  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:16:03 d2.utils.events]: \u001b[0m eta: 1:12:59  iter: 1179  total_loss: 0.7152  loss_cls: 0.3701  loss_box_reg: 0.3274  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.01514  time: 0.5054  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:16:15 d2.utils.events]: \u001b[0m eta: 1:12:55  iter: 1199  total_loss: 0.7262  loss_cls: 0.3296  loss_box_reg: 0.3575  loss_rpn_cls: 0.009532  loss_rpn_loc: 0.01236  time: 0.5069  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:16:27 d2.utils.events]: \u001b[0m eta: 1:12:51  iter: 1219  total_loss: 0.7445  loss_cls: 0.3309  loss_box_reg: 0.3449  loss_rpn_cls: 0.01032  loss_rpn_loc: 0.01696  time: 0.5081  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:16:39 d2.utils.events]: \u001b[0m eta: 1:12:45  iter: 1239  total_loss: 0.7515  loss_cls: 0.3365  loss_box_reg: 0.3769  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.01686  time: 0.5092  data_time: 0.0025  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:16:50 d2.utils.events]: \u001b[0m eta: 1:12:40  iter: 1259  total_loss: 0.7358  loss_cls: 0.3354  loss_box_reg: 0.384  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.01481  time: 0.5102  data_time: 0.0025  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:17:01 d2.utils.events]: \u001b[0m eta: 1:12:36  iter: 1279  total_loss: 0.6177  loss_cls: 0.2996  loss_box_reg: 0.3113  loss_rpn_cls: 0.008271  loss_rpn_loc: 0.01082  time: 0.5110  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:17:12 d2.utils.events]: \u001b[0m eta: 1:12:32  iter: 1299  total_loss: 0.7307  loss_cls: 0.3398  loss_box_reg: 0.3592  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.01376  time: 0.5118  data_time: 0.0025  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:17:24 d2.utils.events]: \u001b[0m eta: 1:12:26  iter: 1319  total_loss: 0.7397  loss_cls: 0.3049  loss_box_reg: 0.3997  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.018  time: 0.5127  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:17:35 d2.utils.events]: \u001b[0m eta: 1:12:24  iter: 1339  total_loss: 0.7694  loss_cls: 0.3423  loss_box_reg: 0.3871  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.01191  time: 0.5135  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:17:47 d2.utils.events]: \u001b[0m eta: 1:12:22  iter: 1359  total_loss: 0.7026  loss_cls: 0.3219  loss_box_reg: 0.3535  loss_rpn_cls: 0.00794  loss_rpn_loc: 0.00925  time: 0.5143  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:17:58 d2.utils.events]: \u001b[0m eta: 1:12:18  iter: 1379  total_loss: 0.8033  loss_cls: 0.336  loss_box_reg: 0.4023  loss_rpn_cls: 0.01027  loss_rpn_loc: 0.01309  time: 0.5151  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:18:09 d2.utils.events]: \u001b[0m eta: 1:12:17  iter: 1399  total_loss: 0.7213  loss_cls: 0.3565  loss_box_reg: 0.3263  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.01563  time: 0.5155  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:18:20 d2.utils.events]: \u001b[0m eta: 1:12:16  iter: 1419  total_loss: 0.6945  loss_cls: 0.3055  loss_box_reg: 0.3468  loss_rpn_cls: 0.01125  loss_rpn_loc: 0.01654  time: 0.5163  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:18:32 d2.utils.events]: \u001b[0m eta: 1:12:18  iter: 1439  total_loss: 0.6624  loss_cls: 0.3003  loss_box_reg: 0.3206  loss_rpn_cls: 0.009396  loss_rpn_loc: 0.01397  time: 0.5171  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:18:43 d2.utils.events]: \u001b[0m eta: 1:12:16  iter: 1459  total_loss: 0.7169  loss_cls: 0.2913  loss_box_reg: 0.3621  loss_rpn_cls: 0.009674  loss_rpn_loc: 0.01289  time: 0.5178  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:18:55 d2.utils.events]: \u001b[0m eta: 1:12:23  iter: 1479  total_loss: 0.7656  loss_cls: 0.356  loss_box_reg: 0.3863  loss_rpn_cls: 0.009679  loss_rpn_loc: 0.01411  time: 0.5186  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:19:06 d2.utils.events]: \u001b[0m eta: 1:12:26  iter: 1499  total_loss: 0.7326  loss_cls: 0.3286  loss_box_reg: 0.3538  loss_rpn_cls: 0.01103  loss_rpn_loc: 0.01281  time: 0.5191  data_time: 0.0025  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:19:17 d2.utils.events]: \u001b[0m eta: 1:12:43  iter: 1519  total_loss: 0.6022  loss_cls: 0.2601  loss_box_reg: 0.3014  loss_rpn_cls: 0.01011  loss_rpn_loc: 0.01234  time: 0.5198  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:19:29 d2.utils.events]: \u001b[0m eta: 1:13:23  iter: 1539  total_loss: 0.6618  loss_cls: 0.3101  loss_box_reg: 0.3529  loss_rpn_cls: 0.01026  loss_rpn_loc: 0.01205  time: 0.5204  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:19:40 d2.utils.events]: \u001b[0m eta: 1:14:08  iter: 1559  total_loss: 0.5865  loss_cls: 0.2808  loss_box_reg: 0.2843  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.01202  time: 0.5210  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:19:51 d2.utils.events]: \u001b[0m eta: 1:14:44  iter: 1579  total_loss: 0.6302  loss_cls: 0.2736  loss_box_reg: 0.3192  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.01025  time: 0.5214  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:20:03 d2.utils.events]: \u001b[0m eta: 1:15:21  iter: 1599  total_loss: 0.5671  loss_cls: 0.2328  loss_box_reg: 0.2688  loss_rpn_cls: 0.0133  loss_rpn_loc: 0.01185  time: 0.5221  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:20:14 d2.utils.events]: \u001b[0m eta: 1:15:38  iter: 1619  total_loss: 0.676  loss_cls: 0.298  loss_box_reg: 0.3206  loss_rpn_cls: 0.01035  loss_rpn_loc: 0.0121  time: 0.5226  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:20:25 d2.utils.events]: \u001b[0m eta: 1:15:50  iter: 1639  total_loss: 0.7112  loss_cls: 0.3178  loss_box_reg: 0.3677  loss_rpn_cls: 0.009855  loss_rpn_loc: 0.01325  time: 0.5230  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:20:36 d2.utils.events]: \u001b[0m eta: 1:16:04  iter: 1659  total_loss: 0.6938  loss_cls: 0.3032  loss_box_reg: 0.3613  loss_rpn_cls: 0.008046  loss_rpn_loc: 0.01418  time: 0.5236  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:20:48 d2.utils.events]: \u001b[0m eta: 1:16:07  iter: 1679  total_loss: 0.6611  loss_cls: 0.298  loss_box_reg: 0.3345  loss_rpn_cls: 0.01007  loss_rpn_loc: 0.01333  time: 0.5240  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:20:59 d2.utils.events]: \u001b[0m eta: 1:16:19  iter: 1699  total_loss: 0.7656  loss_cls: 0.319  loss_box_reg: 0.3915  loss_rpn_cls: 0.01026  loss_rpn_loc: 0.01344  time: 0.5246  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:21:11 d2.utils.events]: \u001b[0m eta: 1:16:18  iter: 1719  total_loss: 0.7023  loss_cls: 0.3332  loss_box_reg: 0.3477  loss_rpn_cls: 0.008122  loss_rpn_loc: 0.01285  time: 0.5255  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:21:23 d2.utils.events]: \u001b[0m eta: 1:16:35  iter: 1739  total_loss: 0.68  loss_cls: 0.2804  loss_box_reg: 0.3425  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.01696  time: 0.5263  data_time: 0.0025  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:21:34 d2.utils.events]: \u001b[0m eta: 1:16:38  iter: 1759  total_loss: 0.7564  loss_cls: 0.309  loss_box_reg: 0.3798  loss_rpn_cls: 0.01044  loss_rpn_loc: 0.01928  time: 0.5268  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:21:46 d2.utils.events]: \u001b[0m eta: 1:16:30  iter: 1779  total_loss: 0.6608  loss_cls: 0.3103  loss_box_reg: 0.3501  loss_rpn_cls: 0.01068  loss_rpn_loc: 0.01424  time: 0.5274  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:21:58 d2.utils.events]: \u001b[0m eta: 1:16:35  iter: 1799  total_loss: 0.6897  loss_cls: 0.3322  loss_box_reg: 0.347  loss_rpn_cls: 0.009595  loss_rpn_loc: 0.01369  time: 0.5280  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:22:09 d2.utils.events]: \u001b[0m eta: 1:16:30  iter: 1819  total_loss: 0.7462  loss_cls: 0.33  loss_box_reg: 0.383  loss_rpn_cls: 0.01032  loss_rpn_loc: 0.01334  time: 0.5284  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:22:21 d2.utils.events]: \u001b[0m eta: 1:16:23  iter: 1839  total_loss: 0.7183  loss_cls: 0.2994  loss_box_reg: 0.371  loss_rpn_cls: 0.008282  loss_rpn_loc: 0.01396  time: 0.5289  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:22:32 d2.utils.events]: \u001b[0m eta: 1:16:23  iter: 1859  total_loss: 0.6761  loss_cls: 0.3  loss_box_reg: 0.3594  loss_rpn_cls: 0.01  loss_rpn_loc: 0.01284  time: 0.5293  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:22:43 d2.utils.events]: \u001b[0m eta: 1:16:17  iter: 1879  total_loss: 0.6339  loss_cls: 0.2902  loss_box_reg: 0.3306  loss_rpn_cls: 0.00858  loss_rpn_loc: 0.01261  time: 0.5298  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:22:55 d2.utils.events]: \u001b[0m eta: 1:16:06  iter: 1899  total_loss: 0.7111  loss_cls: 0.3045  loss_box_reg: 0.3667  loss_rpn_cls: 0.01173  loss_rpn_loc: 0.01354  time: 0.5302  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:23:06 d2.utils.events]: \u001b[0m eta: 1:16:01  iter: 1919  total_loss: 0.6418  loss_cls: 0.277  loss_box_reg: 0.3013  loss_rpn_cls: 0.007988  loss_rpn_loc: 0.01204  time: 0.5306  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:23:18 d2.utils.events]: \u001b[0m eta: 1:15:52  iter: 1939  total_loss: 0.6681  loss_cls: 0.301  loss_box_reg: 0.3642  loss_rpn_cls: 0.006371  loss_rpn_loc: 0.01417  time: 0.5311  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:23:29 d2.utils.events]: \u001b[0m eta: 1:15:51  iter: 1959  total_loss: 0.6691  loss_cls: 0.2906  loss_box_reg: 0.3436  loss_rpn_cls: 0.007758  loss_rpn_loc: 0.01408  time: 0.5315  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:23:40 d2.utils.events]: \u001b[0m eta: 1:15:44  iter: 1979  total_loss: 0.6948  loss_cls: 0.3145  loss_box_reg: 0.3444  loss_rpn_cls: 0.01007  loss_rpn_loc: 0.01121  time: 0.5319  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:23:52 d2.utils.events]: \u001b[0m eta: 1:15:38  iter: 1999  total_loss: 0.6939  loss_cls: 0.2864  loss_box_reg: 0.3591  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.01293  time: 0.5322  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:24:03 d2.utils.events]: \u001b[0m eta: 1:15:29  iter: 2019  total_loss: 0.688  loss_cls: 0.2886  loss_box_reg: 0.3814  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.01636  time: 0.5326  data_time: 0.0025  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:24:15 d2.utils.events]: \u001b[0m eta: 1:15:24  iter: 2039  total_loss: 0.6898  loss_cls: 0.3069  loss_box_reg: 0.3501  loss_rpn_cls: 0.007739  loss_rpn_loc: 0.01252  time: 0.5330  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:24:26 d2.utils.events]: \u001b[0m eta: 1:15:19  iter: 2059  total_loss: 0.6862  loss_cls: 0.3308  loss_box_reg: 0.3055  loss_rpn_cls: 0.008172  loss_rpn_loc: 0.01313  time: 0.5333  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:24:37 d2.utils.events]: \u001b[0m eta: 1:15:13  iter: 2079  total_loss: 0.6727  loss_cls: 0.2809  loss_box_reg: 0.3844  loss_rpn_cls: 0.007364  loss_rpn_loc: 0.01439  time: 0.5337  data_time: 0.0025  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:24:49 d2.utils.events]: \u001b[0m eta: 1:15:06  iter: 2099  total_loss: 0.6591  loss_cls: 0.2731  loss_box_reg: 0.3441  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.01179  time: 0.5342  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:25:01 d2.utils.events]: \u001b[0m eta: 1:15:01  iter: 2119  total_loss: 0.7002  loss_cls: 0.3152  loss_box_reg: 0.3351  loss_rpn_cls: 0.01264  loss_rpn_loc: 0.01494  time: 0.5347  data_time: 0.0029  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:25:13 d2.utils.events]: \u001b[0m eta: 1:14:53  iter: 2139  total_loss: 0.6055  loss_cls: 0.2648  loss_box_reg: 0.3303  loss_rpn_cls: 0.009216  loss_rpn_loc: 0.01157  time: 0.5351  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:25:24 d2.utils.events]: \u001b[0m eta: 1:14:50  iter: 2159  total_loss: 0.6491  loss_cls: 0.2906  loss_box_reg: 0.3313  loss_rpn_cls: 0.008567  loss_rpn_loc: 0.01634  time: 0.5356  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:25:36 d2.utils.events]: \u001b[0m eta: 1:14:44  iter: 2179  total_loss: 0.6095  loss_cls: 0.2458  loss_box_reg: 0.3342  loss_rpn_cls: 0.007162  loss_rpn_loc: 0.01486  time: 0.5360  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:25:47 d2.utils.events]: \u001b[0m eta: 1:14:26  iter: 2199  total_loss: 0.7237  loss_cls: 0.2826  loss_box_reg: 0.3725  loss_rpn_cls: 0.01084  loss_rpn_loc: 0.01651  time: 0.5364  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:25:59 d2.utils.events]: \u001b[0m eta: 1:14:14  iter: 2219  total_loss: 0.6654  loss_cls: 0.3122  loss_box_reg: 0.3332  loss_rpn_cls: 0.01095  loss_rpn_loc: 0.01352  time: 0.5366  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:26:10 d2.utils.events]: \u001b[0m eta: 1:14:03  iter: 2239  total_loss: 0.6235  loss_cls: 0.271  loss_box_reg: 0.3018  loss_rpn_cls: 0.008772  loss_rpn_loc: 0.01316  time: 0.5369  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:26:22 d2.utils.events]: \u001b[0m eta: 1:13:58  iter: 2259  total_loss: 0.6847  loss_cls: 0.3205  loss_box_reg: 0.36  loss_rpn_cls: 0.009415  loss_rpn_loc: 0.01213  time: 0.5373  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:26:33 d2.utils.events]: \u001b[0m eta: 1:13:49  iter: 2279  total_loss: 0.5856  loss_cls: 0.2869  loss_box_reg: 0.2973  loss_rpn_cls: 0.009813  loss_rpn_loc: 0.01443  time: 0.5377  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:26:45 d2.utils.events]: \u001b[0m eta: 1:13:43  iter: 2299  total_loss: 0.6846  loss_cls: 0.2957  loss_box_reg: 0.359  loss_rpn_cls: 0.008929  loss_rpn_loc: 0.01329  time: 0.5381  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:26:57 d2.utils.events]: \u001b[0m eta: 1:13:34  iter: 2319  total_loss: 0.6031  loss_cls: 0.2751  loss_box_reg: 0.312  loss_rpn_cls: 0.008494  loss_rpn_loc: 0.01153  time: 0.5386  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:27:09 d2.utils.events]: \u001b[0m eta: 1:13:24  iter: 2339  total_loss: 0.7559  loss_cls: 0.3226  loss_box_reg: 0.3776  loss_rpn_cls: 0.008144  loss_rpn_loc: 0.01483  time: 0.5392  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:27:21 d2.utils.events]: \u001b[0m eta: 1:13:18  iter: 2359  total_loss: 0.7079  loss_cls: 0.2885  loss_box_reg: 0.3804  loss_rpn_cls: 0.006941  loss_rpn_loc: 0.01594  time: 0.5396  data_time: 0.0029  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:27:32 d2.utils.events]: \u001b[0m eta: 1:13:09  iter: 2379  total_loss: 0.6337  loss_cls: 0.2861  loss_box_reg: 0.3264  loss_rpn_cls: 0.007338  loss_rpn_loc: 0.0121  time: 0.5399  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:27:44 d2.utils.events]: \u001b[0m eta: 1:12:58  iter: 2399  total_loss: 0.5894  loss_cls: 0.2827  loss_box_reg: 0.3195  loss_rpn_cls: 0.008455  loss_rpn_loc: 0.01376  time: 0.5401  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:27:56 d2.utils.events]: \u001b[0m eta: 1:12:49  iter: 2419  total_loss: 0.8258  loss_cls: 0.3592  loss_box_reg: 0.4175  loss_rpn_cls: 0.008759  loss_rpn_loc: 0.01588  time: 0.5408  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:28:08 d2.utils.events]: \u001b[0m eta: 1:12:40  iter: 2439  total_loss: 0.6737  loss_cls: 0.2834  loss_box_reg: 0.3441  loss_rpn_cls: 0.008629  loss_rpn_loc: 0.01392  time: 0.5413  data_time: 0.0029  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:28:21 d2.utils.events]: \u001b[0m eta: 1:12:33  iter: 2459  total_loss: 0.7969  loss_cls: 0.3292  loss_box_reg: 0.4274  loss_rpn_cls: 0.008168  loss_rpn_loc: 0.01502  time: 0.5420  data_time: 0.0029  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:28:33 d2.utils.events]: \u001b[0m eta: 1:12:23  iter: 2479  total_loss: 0.6592  loss_cls: 0.2811  loss_box_reg: 0.3139  loss_rpn_cls: 0.007861  loss_rpn_loc: 0.01374  time: 0.5425  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:28:45 d2.utils.events]: \u001b[0m eta: 1:12:17  iter: 2499  total_loss: 0.6449  loss_cls: 0.2936  loss_box_reg: 0.3159  loss_rpn_cls: 0.007742  loss_rpn_loc: 0.01268  time: 0.5432  data_time: 0.0030  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:28:58 d2.utils.events]: \u001b[0m eta: 1:12:10  iter: 2519  total_loss: 0.705  loss_cls: 0.299  loss_box_reg: 0.3682  loss_rpn_cls: 0.007887  loss_rpn_loc: 0.01326  time: 0.5437  data_time: 0.0029  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:29:10 d2.utils.events]: \u001b[0m eta: 1:12:02  iter: 2539  total_loss: 0.5331  loss_cls: 0.2355  loss_box_reg: 0.2919  loss_rpn_cls: 0.005761  loss_rpn_loc: 0.01125  time: 0.5441  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:29:22 d2.utils.events]: \u001b[0m eta: 1:11:58  iter: 2559  total_loss: 0.7045  loss_cls: 0.2935  loss_box_reg: 0.3513  loss_rpn_cls: 0.006842  loss_rpn_loc: 0.01385  time: 0.5448  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:29:35 d2.utils.events]: \u001b[0m eta: 1:11:52  iter: 2579  total_loss: 0.6984  loss_cls: 0.306  loss_box_reg: 0.3818  loss_rpn_cls: 0.005979  loss_rpn_loc: 0.01301  time: 0.5454  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:29:46 d2.utils.events]: \u001b[0m eta: 1:11:41  iter: 2599  total_loss: 0.6198  loss_cls: 0.2702  loss_box_reg: 0.3037  loss_rpn_cls: 0.008851  loss_rpn_loc: 0.01142  time: 0.5458  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:29:58 d2.utils.events]: \u001b[0m eta: 1:11:33  iter: 2619  total_loss: 0.558  loss_cls: 0.2362  loss_box_reg: 0.2916  loss_rpn_cls: 0.008999  loss_rpn_loc: 0.01173  time: 0.5462  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:30:10 d2.utils.events]: \u001b[0m eta: 1:11:23  iter: 2639  total_loss: 0.6082  loss_cls: 0.2813  loss_box_reg: 0.3469  loss_rpn_cls: 0.009119  loss_rpn_loc: 0.01201  time: 0.5466  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:30:22 d2.utils.events]: \u001b[0m eta: 1:11:14  iter: 2659  total_loss: 0.6734  loss_cls: 0.2763  loss_box_reg: 0.3319  loss_rpn_cls: 0.007552  loss_rpn_loc: 0.01249  time: 0.5469  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:30:34 d2.utils.events]: \u001b[0m eta: 1:11:05  iter: 2679  total_loss: 0.6862  loss_cls: 0.3048  loss_box_reg: 0.3499  loss_rpn_cls: 0.01271  loss_rpn_loc: 0.01413  time: 0.5472  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:30:46 d2.utils.events]: \u001b[0m eta: 1:10:57  iter: 2699  total_loss: 0.6162  loss_cls: 0.2622  loss_box_reg: 0.3204  loss_rpn_cls: 0.008895  loss_rpn_loc: 0.01159  time: 0.5476  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:30:55 d2.utils.events]: \u001b[0m eta: 1:10:37  iter: 2719  total_loss: 0.6609  loss_cls: 0.3034  loss_box_reg: 0.3591  loss_rpn_cls: 0.009193  loss_rpn_loc: 0.01206  time: 0.5470  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:31:04 d2.utils.events]: \u001b[0m eta: 1:10:23  iter: 2739  total_loss: 0.6489  loss_cls: 0.2763  loss_box_reg: 0.3457  loss_rpn_cls: 0.008355  loss_rpn_loc: 0.01045  time: 0.5463  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:31:13 d2.utils.events]: \u001b[0m eta: 1:10:07  iter: 2759  total_loss: 0.65  loss_cls: 0.2746  loss_box_reg: 0.323  loss_rpn_cls: 0.009778  loss_rpn_loc: 0.01108  time: 0.5456  data_time: 0.0025  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:31:23 d2.utils.events]: \u001b[0m eta: 1:09:50  iter: 2779  total_loss: 0.7243  loss_cls: 0.3287  loss_box_reg: 0.36  loss_rpn_cls: 0.009376  loss_rpn_loc: 0.01046  time: 0.5453  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:31:32 d2.utils.events]: \u001b[0m eta: 1:09:31  iter: 2799  total_loss: 0.6767  loss_cls: 0.2816  loss_box_reg: 0.3644  loss_rpn_cls: 0.007641  loss_rpn_loc: 0.01471  time: 0.5445  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:31:43 d2.utils.events]: \u001b[0m eta: 1:09:17  iter: 2819  total_loss: 0.7247  loss_cls: 0.3067  loss_box_reg: 0.3547  loss_rpn_cls: 0.008025  loss_rpn_loc: 0.01206  time: 0.5445  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:31:53 d2.utils.events]: \u001b[0m eta: 1:09:02  iter: 2839  total_loss: 0.5649  loss_cls: 0.258  loss_box_reg: 0.2805  loss_rpn_cls: 0.008657  loss_rpn_loc: 0.01182  time: 0.5444  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:32:05 d2.utils.events]: \u001b[0m eta: 1:08:51  iter: 2859  total_loss: 0.6992  loss_cls: 0.3124  loss_box_reg: 0.3764  loss_rpn_cls: 0.007254  loss_rpn_loc: 0.01416  time: 0.5446  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:32:17 d2.utils.events]: \u001b[0m eta: 1:08:41  iter: 2879  total_loss: 0.6143  loss_cls: 0.2508  loss_box_reg: 0.3364  loss_rpn_cls: 0.007202  loss_rpn_loc: 0.01206  time: 0.5448  data_time: 0.0030  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:32:29 d2.utils.events]: \u001b[0m eta: 1:08:33  iter: 2899  total_loss: 0.6771  loss_cls: 0.2837  loss_box_reg: 0.3608  loss_rpn_cls: 0.008077  loss_rpn_loc: 0.01262  time: 0.5453  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:32:40 d2.utils.events]: \u001b[0m eta: 1:08:21  iter: 2919  total_loss: 0.7274  loss_cls: 0.322  loss_box_reg: 0.3702  loss_rpn_cls: 0.009594  loss_rpn_loc: 0.01201  time: 0.5455  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:32:53 d2.utils.events]: \u001b[0m eta: 1:08:15  iter: 2939  total_loss: 0.6127  loss_cls: 0.2666  loss_box_reg: 0.3068  loss_rpn_cls: 0.009654  loss_rpn_loc: 0.01065  time: 0.5460  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:33:04 d2.utils.events]: \u001b[0m eta: 1:08:07  iter: 2959  total_loss: 0.7223  loss_cls: 0.2953  loss_box_reg: 0.3866  loss_rpn_cls: 0.01058  loss_rpn_loc: 0.01784  time: 0.5462  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:33:16 d2.utils.events]: \u001b[0m eta: 1:07:58  iter: 2979  total_loss: 0.5842  loss_cls: 0.2389  loss_box_reg: 0.339  loss_rpn_cls: 0.01006  loss_rpn_loc: 0.01105  time: 0.5465  data_time: 0.0029  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:33:28 d2.utils.events]: \u001b[0m eta: 1:07:47  iter: 2999  total_loss: 0.678  loss_cls: 0.2927  loss_box_reg: 0.3426  loss_rpn_cls: 0.00828  loss_rpn_loc: 0.01145  time: 0.5469  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:33:41 d2.utils.events]: \u001b[0m eta: 1:07:41  iter: 3019  total_loss: 0.6417  loss_cls: 0.2929  loss_box_reg: 0.3224  loss_rpn_cls: 0.005815  loss_rpn_loc: 0.01333  time: 0.5474  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:33:53 d2.utils.events]: \u001b[0m eta: 1:07:31  iter: 3039  total_loss: 0.624  loss_cls: 0.2709  loss_box_reg: 0.335  loss_rpn_cls: 0.007251  loss_rpn_loc: 0.01134  time: 0.5478  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:34:05 d2.utils.events]: \u001b[0m eta: 1:07:22  iter: 3059  total_loss: 0.7099  loss_cls: 0.307  loss_box_reg: 0.386  loss_rpn_cls: 0.009184  loss_rpn_loc: 0.0127  time: 0.5481  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:34:17 d2.utils.events]: \u001b[0m eta: 1:07:12  iter: 3079  total_loss: 0.6577  loss_cls: 0.3008  loss_box_reg: 0.3414  loss_rpn_cls: 0.006563  loss_rpn_loc: 0.01072  time: 0.5484  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:34:29 d2.utils.events]: \u001b[0m eta: 1:07:02  iter: 3099  total_loss: 0.6528  loss_cls: 0.2778  loss_box_reg: 0.3533  loss_rpn_cls: 0.006874  loss_rpn_loc: 0.01242  time: 0.5488  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:34:41 d2.utils.events]: \u001b[0m eta: 1:06:51  iter: 3119  total_loss: 0.6199  loss_cls: 0.2644  loss_box_reg: 0.3406  loss_rpn_cls: 0.005691  loss_rpn_loc: 0.01355  time: 0.5490  data_time: 0.0029  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:34:52 d2.utils.events]: \u001b[0m eta: 1:06:40  iter: 3139  total_loss: 0.7118  loss_cls: 0.3037  loss_box_reg: 0.3716  loss_rpn_cls: 0.006457  loss_rpn_loc: 0.01097  time: 0.5493  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:35:04 d2.utils.events]: \u001b[0m eta: 1:06:29  iter: 3159  total_loss: 0.6769  loss_cls: 0.3091  loss_box_reg: 0.3385  loss_rpn_cls: 0.008831  loss_rpn_loc: 0.01211  time: 0.5495  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:35:16 d2.utils.events]: \u001b[0m eta: 1:06:19  iter: 3179  total_loss: 0.6056  loss_cls: 0.2364  loss_box_reg: 0.343  loss_rpn_cls: 0.007291  loss_rpn_loc: 0.009985  time: 0.5499  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:35:28 d2.utils.events]: \u001b[0m eta: 1:06:10  iter: 3199  total_loss: 0.7681  loss_cls: 0.2968  loss_box_reg: 0.3969  loss_rpn_cls: 0.01018  loss_rpn_loc: 0.01567  time: 0.5502  data_time: 0.0030  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:35:40 d2.utils.events]: \u001b[0m eta: 1:06:00  iter: 3219  total_loss: 0.7257  loss_cls: 0.33  loss_box_reg: 0.3755  loss_rpn_cls: 0.008455  loss_rpn_loc: 0.01618  time: 0.5504  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:35:52 d2.utils.events]: \u001b[0m eta: 1:05:55  iter: 3239  total_loss: 0.6525  loss_cls: 0.2885  loss_box_reg: 0.338  loss_rpn_cls: 0.009483  loss_rpn_loc: 0.01171  time: 0.5509  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:36:04 d2.utils.events]: \u001b[0m eta: 1:05:43  iter: 3259  total_loss: 0.6111  loss_cls: 0.2892  loss_box_reg: 0.3011  loss_rpn_cls: 0.007519  loss_rpn_loc: 0.008882  time: 0.5511  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:36:16 d2.utils.events]: \u001b[0m eta: 1:05:34  iter: 3279  total_loss: 0.7055  loss_cls: 0.2551  loss_box_reg: 0.3535  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.01368  time: 0.5514  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:36:26 d2.utils.events]: \u001b[0m eta: 1:05:18  iter: 3299  total_loss: 0.5759  loss_cls: 0.2344  loss_box_reg: 0.3093  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.01229  time: 0.5511  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:36:36 d2.utils.events]: \u001b[0m eta: 1:05:02  iter: 3319  total_loss: 0.6795  loss_cls: 0.2731  loss_box_reg: 0.3613  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.01371  time: 0.5507  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:36:45 d2.utils.events]: \u001b[0m eta: 1:04:44  iter: 3339  total_loss: 0.6479  loss_cls: 0.2924  loss_box_reg: 0.329  loss_rpn_cls: 0.01047  loss_rpn_loc: 0.0156  time: 0.5503  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:36:55 d2.utils.events]: \u001b[0m eta: 1:04:28  iter: 3359  total_loss: 0.6708  loss_cls: 0.2821  loss_box_reg: 0.3592  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.01429  time: 0.5497  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:37:06 d2.utils.events]: \u001b[0m eta: 1:04:17  iter: 3379  total_loss: 0.6438  loss_cls: 0.2528  loss_box_reg: 0.3636  loss_rpn_cls: 0.007416  loss_rpn_loc: 0.01371  time: 0.5497  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:37:19 d2.utils.events]: \u001b[0m eta: 1:04:12  iter: 3399  total_loss: 0.6637  loss_cls: 0.2773  loss_box_reg: 0.3484  loss_rpn_cls: 0.008394  loss_rpn_loc: 0.01108  time: 0.5504  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:37:31 d2.utils.events]: \u001b[0m eta: 1:03:59  iter: 3419  total_loss: 0.5749  loss_cls: 0.237  loss_box_reg: 0.3311  loss_rpn_cls: 0.008251  loss_rpn_loc: 0.01013  time: 0.5506  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:37:43 d2.utils.events]: \u001b[0m eta: 1:03:46  iter: 3439  total_loss: 0.7269  loss_cls: 0.3073  loss_box_reg: 0.3749  loss_rpn_cls: 0.007174  loss_rpn_loc: 0.01226  time: 0.5510  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:37:55 d2.utils.events]: \u001b[0m eta: 1:03:34  iter: 3459  total_loss: 0.6426  loss_cls: 0.293  loss_box_reg: 0.3569  loss_rpn_cls: 0.006866  loss_rpn_loc: 0.01129  time: 0.5513  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:38:08 d2.utils.events]: \u001b[0m eta: 1:03:26  iter: 3479  total_loss: 0.6001  loss_cls: 0.2448  loss_box_reg: 0.3192  loss_rpn_cls: 0.009606  loss_rpn_loc: 0.01166  time: 0.5518  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:38:20 d2.utils.events]: \u001b[0m eta: 1:03:11  iter: 3499  total_loss: 0.6459  loss_cls: 0.2734  loss_box_reg: 0.353  loss_rpn_cls: 0.008582  loss_rpn_loc: 0.01303  time: 0.5520  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:38:32 d2.utils.events]: \u001b[0m eta: 1:02:55  iter: 3519  total_loss: 0.6699  loss_cls: 0.2757  loss_box_reg: 0.3562  loss_rpn_cls: 0.009159  loss_rpn_loc: 0.01385  time: 0.5524  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:38:44 d2.utils.events]: \u001b[0m eta: 1:02:41  iter: 3539  total_loss: 0.6649  loss_cls: 0.2861  loss_box_reg: 0.3263  loss_rpn_cls: 0.008558  loss_rpn_loc: 0.01224  time: 0.5527  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:38:57 d2.utils.events]: \u001b[0m eta: 1:02:28  iter: 3559  total_loss: 0.6808  loss_cls: 0.3114  loss_box_reg: 0.3462  loss_rpn_cls: 0.008168  loss_rpn_loc: 0.0123  time: 0.5531  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:39:09 d2.utils.events]: \u001b[0m eta: 1:02:16  iter: 3579  total_loss: 0.7566  loss_cls: 0.329  loss_box_reg: 0.3742  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.01566  time: 0.5535  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:39:21 d2.utils.events]: \u001b[0m eta: 1:02:05  iter: 3599  total_loss: 0.7013  loss_cls: 0.2992  loss_box_reg: 0.3674  loss_rpn_cls: 0.006184  loss_rpn_loc: 0.01358  time: 0.5537  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:39:33 d2.utils.events]: \u001b[0m eta: 1:01:54  iter: 3619  total_loss: 0.7098  loss_cls: 0.2868  loss_box_reg: 0.3818  loss_rpn_cls: 0.00748  loss_rpn_loc: 0.01468  time: 0.5540  data_time: 0.0029  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:39:45 d2.utils.events]: \u001b[0m eta: 1:01:38  iter: 3639  total_loss: 0.7701  loss_cls: 0.2707  loss_box_reg: 0.4346  loss_rpn_cls: 0.008818  loss_rpn_loc: 0.01899  time: 0.5542  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:39:57 d2.utils.events]: \u001b[0m eta: 1:01:24  iter: 3659  total_loss: 0.646  loss_cls: 0.2904  loss_box_reg: 0.3248  loss_rpn_cls: 0.01083  loss_rpn_loc: 0.01305  time: 0.5544  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:40:09 d2.utils.events]: \u001b[0m eta: 1:01:17  iter: 3679  total_loss: 0.6735  loss_cls: 0.3041  loss_box_reg: 0.3539  loss_rpn_cls: 0.008661  loss_rpn_loc: 0.01258  time: 0.5548  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:40:22 d2.utils.events]: \u001b[0m eta: 1:01:07  iter: 3699  total_loss: 0.704  loss_cls: 0.2971  loss_box_reg: 0.3689  loss_rpn_cls: 0.006371  loss_rpn_loc: 0.01391  time: 0.5552  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:40:34 d2.utils.events]: \u001b[0m eta: 1:01:02  iter: 3719  total_loss: 0.6141  loss_cls: 0.289  loss_box_reg: 0.3249  loss_rpn_cls: 0.008424  loss_rpn_loc: 0.01301  time: 0.5555  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:40:46 d2.utils.events]: \u001b[0m eta: 1:00:57  iter: 3739  total_loss: 0.6693  loss_cls: 0.2912  loss_box_reg: 0.3914  loss_rpn_cls: 0.008152  loss_rpn_loc: 0.01532  time: 0.5557  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:41:00 d2.utils.events]: \u001b[0m eta: 1:00:57  iter: 3759  total_loss: 0.5409  loss_cls: 0.2629  loss_box_reg: 0.2768  loss_rpn_cls: 0.009079  loss_rpn_loc: 0.0117  time: 0.5563  data_time: 0.0029  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:41:12 d2.utils.events]: \u001b[0m eta: 1:00:50  iter: 3779  total_loss: 0.6601  loss_cls: 0.2655  loss_box_reg: 0.3904  loss_rpn_cls: 0.006645  loss_rpn_loc: 0.01366  time: 0.5566  data_time: 0.0029  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:41:23 d2.utils.events]: \u001b[0m eta: 1:00:44  iter: 3799  total_loss: 0.6303  loss_cls: 0.2654  loss_box_reg: 0.364  loss_rpn_cls: 0.005702  loss_rpn_loc: 0.0119  time: 0.5566  data_time: 0.0029  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:41:35 d2.utils.events]: \u001b[0m eta: 1:00:37  iter: 3819  total_loss: 0.6535  loss_cls: 0.2833  loss_box_reg: 0.3402  loss_rpn_cls: 0.008622  loss_rpn_loc: 0.01019  time: 0.5568  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:41:47 d2.utils.events]: \u001b[0m eta: 1:00:33  iter: 3839  total_loss: 0.7053  loss_cls: 0.2732  loss_box_reg: 0.3755  loss_rpn_cls: 0.005069  loss_rpn_loc: 0.01337  time: 0.5570  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:41:58 d2.utils.events]: \u001b[0m eta: 1:00:19  iter: 3859  total_loss: 0.6771  loss_cls: 0.2937  loss_box_reg: 0.3794  loss_rpn_cls: 0.00664  loss_rpn_loc: 0.01237  time: 0.5571  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:42:11 d2.utils.events]: \u001b[0m eta: 1:00:14  iter: 3879  total_loss: 0.6491  loss_cls: 0.2821  loss_box_reg: 0.3505  loss_rpn_cls: 0.006823  loss_rpn_loc: 0.01336  time: 0.5576  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:42:24 d2.utils.events]: \u001b[0m eta: 1:00:01  iter: 3899  total_loss: 0.6512  loss_cls: 0.2968  loss_box_reg: 0.3635  loss_rpn_cls: 0.005519  loss_rpn_loc: 0.01338  time: 0.5579  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:42:36 d2.utils.events]: \u001b[0m eta: 0:59:51  iter: 3919  total_loss: 0.677  loss_cls: 0.298  loss_box_reg: 0.3728  loss_rpn_cls: 0.007706  loss_rpn_loc: 0.01531  time: 0.5583  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:42:48 d2.utils.events]: \u001b[0m eta: 0:59:37  iter: 3939  total_loss: 0.6606  loss_cls: 0.2685  loss_box_reg: 0.344  loss_rpn_cls: 0.008429  loss_rpn_loc: 0.01266  time: 0.5585  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:43:00 d2.utils.events]: \u001b[0m eta: 0:59:27  iter: 3959  total_loss: 0.7415  loss_cls: 0.3366  loss_box_reg: 0.3867  loss_rpn_cls: 0.009078  loss_rpn_loc: 0.01284  time: 0.5586  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:43:13 d2.utils.events]: \u001b[0m eta: 0:59:17  iter: 3979  total_loss: 0.6734  loss_cls: 0.2706  loss_box_reg: 0.3564  loss_rpn_cls: 0.008854  loss_rpn_loc: 0.01716  time: 0.5590  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:43:25 d2.utils.events]: \u001b[0m eta: 0:59:06  iter: 3999  total_loss: 0.7318  loss_cls: 0.3079  loss_box_reg: 0.3963  loss_rpn_cls: 0.007536  loss_rpn_loc: 0.01516  time: 0.5593  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:43:38 d2.utils.events]: \u001b[0m eta: 0:58:53  iter: 4019  total_loss: 0.6644  loss_cls: 0.2943  loss_box_reg: 0.3724  loss_rpn_cls: 0.007407  loss_rpn_loc: 0.01114  time: 0.5597  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:43:50 d2.utils.events]: \u001b[0m eta: 0:58:42  iter: 4039  total_loss: 0.6968  loss_cls: 0.2908  loss_box_reg: 0.3612  loss_rpn_cls: 0.00759  loss_rpn_loc: 0.01338  time: 0.5599  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:44:02 d2.utils.events]: \u001b[0m eta: 0:58:32  iter: 4059  total_loss: 0.6405  loss_cls: 0.2905  loss_box_reg: 0.3381  loss_rpn_cls: 0.007059  loss_rpn_loc: 0.0119  time: 0.5603  data_time: 0.0029  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:44:12 d2.utils.events]: \u001b[0m eta: 0:58:18  iter: 4079  total_loss: 0.7577  loss_cls: 0.2992  loss_box_reg: 0.3783  loss_rpn_cls: 0.0076  loss_rpn_loc: 0.01678  time: 0.5598  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:44:20 d2.utils.events]: \u001b[0m eta: 0:58:01  iter: 4099  total_loss: 0.6535  loss_cls: 0.2562  loss_box_reg: 0.3365  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.0165  time: 0.5591  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:44:30 d2.utils.events]: \u001b[0m eta: 0:57:45  iter: 4119  total_loss: 0.6556  loss_cls: 0.271  loss_box_reg: 0.3444  loss_rpn_cls: 0.008965  loss_rpn_loc: 0.01338  time: 0.5587  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:44:40 d2.utils.events]: \u001b[0m eta: 0:57:32  iter: 4139  total_loss: 0.6772  loss_cls: 0.282  loss_box_reg: 0.3649  loss_rpn_cls: 0.006735  loss_rpn_loc: 0.01383  time: 0.5584  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:44:49 d2.utils.events]: \u001b[0m eta: 0:57:16  iter: 4159  total_loss: 0.6772  loss_cls: 0.2685  loss_box_reg: 0.3889  loss_rpn_cls: 0.007511  loss_rpn_loc: 0.0117  time: 0.5581  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:45:03 d2.utils.events]: \u001b[0m eta: 0:57:08  iter: 4179  total_loss: 0.6259  loss_cls: 0.2766  loss_box_reg: 0.3052  loss_rpn_cls: 0.006133  loss_rpn_loc: 0.01089  time: 0.5586  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:45:16 d2.utils.events]: \u001b[0m eta: 0:56:57  iter: 4199  total_loss: 0.6563  loss_cls: 0.2611  loss_box_reg: 0.3577  loss_rpn_cls: 0.004767  loss_rpn_loc: 0.009644  time: 0.5590  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:45:29 d2.utils.events]: \u001b[0m eta: 0:56:50  iter: 4219  total_loss: 0.6673  loss_cls: 0.2791  loss_box_reg: 0.3554  loss_rpn_cls: 0.006528  loss_rpn_loc: 0.0116  time: 0.5594  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:45:40 d2.utils.events]: \u001b[0m eta: 0:56:35  iter: 4239  total_loss: 0.6588  loss_cls: 0.2951  loss_box_reg: 0.3595  loss_rpn_cls: 0.00575  loss_rpn_loc: 0.01099  time: 0.5595  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:45:53 d2.utils.events]: \u001b[0m eta: 0:56:25  iter: 4259  total_loss: 0.6231  loss_cls: 0.3118  loss_box_reg: 0.3322  loss_rpn_cls: 0.007225  loss_rpn_loc: 0.01278  time: 0.5600  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:46:07 d2.utils.events]: \u001b[0m eta: 0:56:18  iter: 4279  total_loss: 0.7113  loss_cls: 0.3184  loss_box_reg: 0.4168  loss_rpn_cls: 0.005782  loss_rpn_loc: 0.01233  time: 0.5606  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:46:19 d2.utils.events]: \u001b[0m eta: 0:56:08  iter: 4299  total_loss: 0.7088  loss_cls: 0.287  loss_box_reg: 0.3492  loss_rpn_cls: 0.006043  loss_rpn_loc: 0.01529  time: 0.5608  data_time: 0.0029  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:46:30 d2.utils.events]: \u001b[0m eta: 0:55:59  iter: 4319  total_loss: 0.6987  loss_cls: 0.3214  loss_box_reg: 0.3778  loss_rpn_cls: 0.008371  loss_rpn_loc: 0.01352  time: 0.5607  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:46:38 d2.utils.events]: \u001b[0m eta: 0:55:47  iter: 4339  total_loss: 0.694  loss_cls: 0.3072  loss_box_reg: 0.3735  loss_rpn_cls: 0.00822  loss_rpn_loc: 0.01283  time: 0.5600  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:46:47 d2.utils.events]: \u001b[0m eta: 0:55:34  iter: 4359  total_loss: 0.683  loss_cls: 0.2938  loss_box_reg: 0.4077  loss_rpn_cls: 0.007914  loss_rpn_loc: 0.01349  time: 0.5595  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:46:57 d2.utils.events]: \u001b[0m eta: 0:55:20  iter: 4379  total_loss: 0.5963  loss_cls: 0.2379  loss_box_reg: 0.297  loss_rpn_cls: 0.00513  loss_rpn_loc: 0.0087  time: 0.5592  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:47:16 d2.utils.events]: \u001b[0m eta: 0:55:09  iter: 4399  total_loss: 0.6161  loss_cls: 0.2493  loss_box_reg: 0.3367  loss_rpn_cls: 0.006843  loss_rpn_loc: 0.0145  time: 0.5610  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:47:25 d2.utils.events]: \u001b[0m eta: 0:54:53  iter: 4419  total_loss: 0.6572  loss_cls: 0.2588  loss_box_reg: 0.368  loss_rpn_cls: 0.006612  loss_rpn_loc: 0.01156  time: 0.5605  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:47:40 d2.utils.events]: \u001b[0m eta: 0:54:45  iter: 4439  total_loss: 0.6672  loss_cls: 0.3301  loss_box_reg: 0.3588  loss_rpn_cls: 0.006933  loss_rpn_loc: 0.01216  time: 0.5613  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:47:55 d2.utils.events]: \u001b[0m eta: 0:54:34  iter: 4459  total_loss: 0.6853  loss_cls: 0.2479  loss_box_reg: 0.3867  loss_rpn_cls: 0.006804  loss_rpn_loc: 0.01698  time: 0.5622  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:48:13 d2.utils.events]: \u001b[0m eta: 0:54:24  iter: 4479  total_loss: 0.6344  loss_cls: 0.2787  loss_box_reg: 0.3361  loss_rpn_cls: 0.007001  loss_rpn_loc: 0.01082  time: 0.5637  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:48:29 d2.utils.events]: \u001b[0m eta: 0:54:17  iter: 4499  total_loss: 0.6284  loss_cls: 0.3004  loss_box_reg: 0.3423  loss_rpn_cls: 0.005984  loss_rpn_loc: 0.01327  time: 0.5646  data_time: 0.0028  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:48:38 d2.utils.events]: \u001b[0m eta: 0:53:58  iter: 4519  total_loss: 0.6925  loss_cls: 0.3146  loss_box_reg: 0.3058  loss_rpn_cls: 0.006614  loss_rpn_loc: 0.01033  time: 0.5643  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:48:48 d2.utils.events]: \u001b[0m eta: 0:53:41  iter: 4539  total_loss: 0.5742  loss_cls: 0.2541  loss_box_reg: 0.348  loss_rpn_cls: 0.008014  loss_rpn_loc: 0.01416  time: 0.5639  data_time: 0.0027  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:48:59 d2.utils.events]: \u001b[0m eta: 0:53:23  iter: 4559  total_loss: 0.5497  loss_cls: 0.2291  loss_box_reg: 0.2862  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.0124  time: 0.5637  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n",
      "\u001b[32m[01/27 20:48:59 d2.engine.hooks]: \u001b[0mOverall training speed: 4558 iterations in 0:42:49 (0.5638 s / it)\n",
      "\u001b[32m[01/27 20:48:59 d2.engine.hooks]: \u001b[0mTotal training time: 0:42:50 (0:00:01 on hooks)\n",
      "\u001b[32m[01/27 20:48:59 d2.utils.events]: \u001b[0m eta: 0:53:23  iter: 4560  total_loss: 0.5497  loss_cls: 0.2291  loss_box_reg: 0.2862  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.0124  time: 0.5637  data_time: 0.0026  lr: 0.0125  max_mem: 5415M\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jehad\\gitProjects\\Smart-City-AI\\Test1.ipynb Cell 8\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jehad/gitProjects/Smart-City-AI/Test1.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m trainer \u001b[39m=\u001b[39m DefaultTrainer(cfg) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jehad/gitProjects/Smart-City-AI/Test1.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m trainer\u001b[39m.\u001b[39mresume_or_load(resume\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jehad/gitProjects/Smart-City-AI/Test1.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\detectron2\\engine\\defaults.py:484\u001b[0m, in \u001b[0;36mDefaultTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \u001b[39m    Run training.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \n\u001b[0;32m    481\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[39m        OrderedDict of results, if evaluation is enabled. Otherwise None.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mtrain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart_iter, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter)\n\u001b[0;32m    485\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mTEST\u001b[39m.\u001b[39mEXPECTED_RESULTS) \u001b[39mand\u001b[39;00m comm\u001b[39m.\u001b[39mis_main_process():\n\u001b[0;32m    486\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mhasattr\u001b[39m(\n\u001b[0;32m    487\u001b[0m             \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_last_eval_results\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    488\u001b[0m         ), \u001b[39m\"\u001b[39m\u001b[39mNo evaluation results obtained during training!\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\detectron2\\engine\\train_loop.py:149\u001b[0m, in \u001b[0;36mTrainerBase.train\u001b[1;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_iter, max_iter):\n\u001b[0;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbefore_step()\n\u001b[1;32m--> 149\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_step()\n\u001b[0;32m    150\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter_step()\n\u001b[0;32m    151\u001b[0m \u001b[39m# self.iter == max_iter can be used by `after_train` to\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[39m# tell whether the training successfully finished or failed\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[39m# due to exceptions.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\detectron2\\engine\\defaults.py:494\u001b[0m, in \u001b[0;36mDefaultTrainer.run_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    493\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer\u001b[39m.\u001b[39miter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter\n\u001b[1;32m--> 494\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_trainer\u001b[39m.\u001b[39;49mrun_step()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\detectron2\\engine\\train_loop.py:274\u001b[0m, in \u001b[0;36mSimpleTrainer.run_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    269\u001b[0m data_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter() \u001b[39m-\u001b[39m start\n\u001b[0;32m    271\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[39mIf you want to do something with the losses, you can wrap the model.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m loss_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(data)\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loss_dict, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m    276\u001b[0m     losses \u001b[39m=\u001b[39m loss_dict\n",
      "File \u001b[1;32mc:\\Users\\jehad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\detectron2\\modeling\\meta_arch\\rcnn.py:161\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[1;34m(self, batched_inputs)\u001b[0m\n\u001b[0;32m    158\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackbone(images\u001b[39m.\u001b[39mtensor)\n\u001b[0;32m    160\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproposal_generator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     proposals, proposal_losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproposal_generator(images, features, gt_instances)\n\u001b[0;32m    162\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mproposals\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m batched_inputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jehad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\detectron2\\modeling\\proposal_generator\\rpn.py:452\u001b[0m, in \u001b[0;36mRPN.forward\u001b[1;34m(self, images, features, gt_instances)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[39m    images (ImageList): input images of length `N`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m    loss: dict[Tensor] or None\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    451\u001b[0m features \u001b[39m=\u001b[39m [features[f] \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_features]\n\u001b[1;32m--> 452\u001b[0m anchors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49manchor_generator(features)\n\u001b[0;32m    454\u001b[0m pred_objectness_logits, pred_anchor_deltas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrpn_head(features)\n\u001b[0;32m    455\u001b[0m \u001b[39m# Transpose the Hi*Wi*A dimension to the middle:\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jehad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\detectron2\\modeling\\anchor_generator.py:230\u001b[0m, in \u001b[0;36mDefaultAnchorGenerator.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[39m    features (list[Tensor]): list of backbone feature maps on which to generate anchors.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[39m        where Hi, Wi are resolution of the feature map divided by anchor stride.\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    229\u001b[0m grid_sizes \u001b[39m=\u001b[39m [feature_map\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:] \u001b[39mfor\u001b[39;00m feature_map \u001b[39min\u001b[39;00m features]\n\u001b[1;32m--> 230\u001b[0m anchors_over_all_feature_maps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grid_anchors(grid_sizes)\n\u001b[0;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m [Boxes(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m anchors_over_all_feature_maps]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\detectron2\\modeling\\anchor_generator.py:174\u001b[0m, in \u001b[0;36mDefaultAnchorGenerator._grid_anchors\u001b[1;34m(self, grid_sizes)\u001b[0m\n\u001b[0;32m    172\u001b[0m buffers: List[torch\u001b[39m.\u001b[39mTensor] \u001b[39m=\u001b[39m [x[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell_anchors\u001b[39m.\u001b[39mnamed_buffers()]\n\u001b[0;32m    173\u001b[0m \u001b[39mfor\u001b[39;00m size, stride, base_anchors \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(grid_sizes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrides, buffers):\n\u001b[1;32m--> 174\u001b[0m     shift_x, shift_y \u001b[39m=\u001b[39m _create_grid_offsets(size, stride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moffset, base_anchors)\n\u001b[0;32m    175\u001b[0m     shifts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack((shift_x, shift_y, shift_x, shift_y), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    177\u001b[0m     anchors\u001b[39m.\u001b[39mappend((shifts\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m) \u001b[39m+\u001b[39m base_anchors\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m))\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\detectron2\\modeling\\anchor_generator.py:43\u001b[0m, in \u001b[0;36m_create_grid_offsets\u001b[1;34m(size, stride, offset, target_device_tensor)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_grid_offsets\u001b[39m(\n\u001b[0;32m     40\u001b[0m     size: List[\u001b[39mint\u001b[39m], stride: \u001b[39mint\u001b[39m, offset: \u001b[39mfloat\u001b[39m, target_device_tensor: torch\u001b[39m.\u001b[39mTensor\n\u001b[0;32m     41\u001b[0m ):\n\u001b[0;32m     42\u001b[0m     grid_height, grid_width \u001b[39m=\u001b[39m size\n\u001b[1;32m---> 43\u001b[0m     shifts_x \u001b[39m=\u001b[39m move_device_like(\n\u001b[0;32m     44\u001b[0m         torch\u001b[39m.\u001b[39;49marange(offset \u001b[39m*\u001b[39;49m stride, grid_width \u001b[39m*\u001b[39;49m stride, step\u001b[39m=\u001b[39;49mstride, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32),\n\u001b[0;32m     45\u001b[0m         target_device_tensor,\n\u001b[0;32m     46\u001b[0m     )\n\u001b[0;32m     47\u001b[0m     shifts_y \u001b[39m=\u001b[39m move_device_like(\n\u001b[0;32m     48\u001b[0m         torch\u001b[39m.\u001b[39marange(offset \u001b[39m*\u001b[39m stride, grid_height \u001b[39m*\u001b[39m stride, step\u001b[39m=\u001b[39mstride, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32),\n\u001b[0;32m     49\u001b[0m         target_device_tensor,\n\u001b[0;32m     50\u001b[0m     )\n\u001b[0;32m     52\u001b[0m     shift_y, shift_x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmeshgrid(shifts_y, shifts_x)\n",
      "File \u001b[1;32mc:\\Users\\jehad\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\jit\\_trace.py:1136\u001b[0m, in \u001b[0;36m_script_if_tracing.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(fn)\n\u001b[0;32m   1133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1134\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tracing():\n\u001b[0;32m   1135\u001b[0m         \u001b[39m# Not tracing, don't do anything\u001b[39;00m\n\u001b[1;32m-> 1136\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1138\u001b[0m     compiled_fn \u001b[39m=\u001b[39m script(wrapper\u001b[39m.\u001b[39m__original_fn)  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m     \u001b[39mreturn\u001b[39;00m compiled_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\detectron2\\layers\\wrappers.py:148\u001b[0m, in \u001b[0;36mmove_device_like\u001b[1;34m(src, dst)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mscript_if_tracing\n\u001b[0;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmove_device_like\u001b[39m(src: torch\u001b[39m.\u001b[39mTensor, dst: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m    144\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[39m    Tracing friendly way to cast tensor to another tensor's device. Device will be treated\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39m    as constant during tracing, scripting the casting process as whole can workaround this issue.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m     \u001b[39mreturn\u001b[39;00m src\u001b[39m.\u001b[39;49mto(dst\u001b[39m.\u001b[39;49mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "import os\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")) #Get the basic model configuration from the model zoo \n",
    "cfg.DATASETS.TRAIN = (\"smartcity\",) #Passing the Train and Validation sets\n",
    "cfg.MODEL.DEVICE = \"cuda\"\n",
    "cfg.DATALOADER.NUM_WORKERS = 4 # Number of data loading threads\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4 # Number of images per batch across all machines.\n",
    "cfg.SOLVER.BASE_LR = 0.0125  # pick a good LearningRate\n",
    "cfg.SOLVER.MAX_ITER = 10000  #No. of iterations   \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256  \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 11 # No. of classes \n",
    "cfg.DATASETS.TEST = ()\n",
    "\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 500 # No. of iterations after which the Validation Set is evaluated. \n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/27 20:05:25 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output\\model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"smartcity\", )\n",
    "predictor = DefaultPredictor(cfg)\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "for d in random.sample(dataset_dicts, 10):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=metadata, \n",
    "                   scale=0.8, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imshow(\"image\",v.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919d74488b7f903726046d94a3db12ed6078364356a89db739a4dc274728573d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
